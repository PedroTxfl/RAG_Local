# ğŸ§  RAG Local - Question Answer sobre ICP-Brasil

Este projeto implementa um sistema de **Perguntas e Respostas (Q\&A)** com base em documentos da **ICP-Brasil**, utilizando um modelo local de linguagem (LLM) e embeddings vetoriais persistentes com **ChromaDB**. Ele Ã© ideal para consultas jurÃ­dicas sobre certificaÃ§Ã£o digital baseadas **somente no conteÃºdo fornecido**.

> âœ… Tudo roda localmente. Nenhum dado Ã© enviado para servidores externos.

---

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ data/                # Coloque aqui seus arquivos PDF
â”œâ”€â”€ chroma_db/           # Banco de vetores persistente (gerado automaticamente)
â”œâ”€â”€ main.py              # CÃ³digo principal do projeto
â”œâ”€â”€ requirements.txt     # DependÃªncias do projeto
â””â”€â”€ README.md
```

---

## ğŸš€ Como Rodar o Projeto

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/PedroTxfl/RAG_local_Question-Answer.git
cd RAG_local_Question-Answer
```

### 2. Crie um ambiente virtual

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
.venv\Scripts\activate     # Windows
```

### 3. Instale as dependÃªncias

```bash
pip install -r requirements.txt
```

> ğŸ“Œ **Importante:** Certifique-se de ter o **Python 3.10+** instalado.

### 4. Instale e configure o Ollama

Este projeto utiliza o [Ollama](https://ollama.com/) para rodar o modelo LLM localmente.

* Baixe e instale o Ollama de acordo com seu sistema operacional.
* ApÃ³s instalado, certifique-se de iniciar o servidor Ollama:

```bash
ollama run gemma3:12b
```

### 5. Adicione os documentos

Coloque seus arquivos **.PDF** no diretÃ³rio `/data/`.

> âš ï¸ **AtenÃ§Ã£o:** O sistema sÃ³ indexarÃ¡ arquivos com extensÃ£o `.pdf`. Outros formatos serÃ£o ignorados.

---

## ğŸ› ï¸ PersonalizaÃ§Ã£o

### Modificar o Prompt do Assistente

Caso deseje personalizar o comportamento do modelo (por exemplo, mudar o foco jurÃ­dico, tom da resposta, idioma etc.), edite a variÃ¡vel `template` em `main.py` com o seu prÃ³prio texto orientativo.

---

## ğŸ’¬ Executando o Assistente

Depois de tudo configurado, execute o script principal:

```bash
python main.py
```

VocÃª verÃ¡ a seguinte mensagem:

```
Assistente JurÃ­dico ICP-Brasil (Persistente) - Pergunte algo ou digite 'sair' para encerrar.
```

Agora vocÃª pode comeÃ§ar a interagir com o sistema de perguntas e respostas.

---

## ğŸ“Œ Requisitos

* Python 3.10+
* [Ollama](https://ollama.com/) instalado e em execuÃ§Ã£o
* Ambiente virtual (`venv`) ativo
* Modelos baixados:

  * `gemma3:12b` (via Ollama)
  * `intfloat/multilingual-e5-large` (via Hugging Face)

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob os termos da [MIT License](LICENSE).

---

